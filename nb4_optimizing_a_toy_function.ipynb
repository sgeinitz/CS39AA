{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# CS39AA - Notebook 4: Optimizing of a Toy Loss Function\n",
                "\n",
                "In this short notebook we will look at Gradient Descent as an optimization method. In machine learning, and specifically neural networks, we'll see that this method and extensions of it are how models are trained. In other words, the ideal values for all of the model parameters (i.e. weights and biases) will be found by minimizing the loss function with respect to the parameters. \n",
                "\n",
                "[![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/sgeinitz/CS39AA/blob/main/nb4_optimizing_a_toy_function.ipynb)\n",
                "\n",
                "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sgeinitz/cs39aa_notebooks/blob/main/nb4_optimizing_a_toy_function.ipynb)\n",
                "\n",
                "\n",
                "### 1. Simple Parabola\n",
                "Before defining a loss function we must import the Python modules we'll need. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import matplotlib.pyplot as plt"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We'll now define a hypothetical loss function. \n",
                "\n",
                "* $\\mathrm{Loss}(w) = 0.5 \\cdot (2\\cdot w - 4)^2 + 3$\n",
                "\n",
                "Note that the loss function above is already stated in terms of the our single model parameter, $w$. We'll now define a Python function for the $\\mathrm{Loss}$ and plot it (again, with respect to $w$). "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# define a hypothetical loss function\n",
                "def loss(param_value):\n",
                "    return 0.5 * np.square(2*param_value - 4) + 7\n",
                "\n",
                "# plot loss function\n",
                "ws = np.arange(-15, 20, 0.5)\n",
                "plt.plot(ws, loss(ws))\n",
                "plt.xlabel('w')\n",
                "plt.ylabel('loss')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The function above is a simple parabola, so if we wanted to we could easily find the minimum of this directly. However, using this toy example, let's see how we would find the minimum of this function using gradient descent. Later on, we'll use this same gradient descent approach on more complex functions, when there are hundreds, thousands, or more parameters that we must find the ideal value for. \n",
                "\n",
                "Since we don't know the optimal value of $w$ right away (or are pretending that we don't know), we must start with some initial value of $w$. In practice, weight and bias parameters are initialized to random values that. For our example, let's assume that the initial, or starting value of $w$ is $-7$. We'll call this initial value $w_0$, so that\n",
                "* $w_0 = -7$.\n",
                "\n",
                "To see where this is on the $\\mathrm{Loss}$ function, we will plot the point on the graph. \n",
                "\n",
                "The red point below is precisely at the position $(w_0, \\, \\mathrm{Loss}(w_0))$. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "w0 = -7\n",
                "plt.plot(ws, loss(ws))\n",
                "plt.scatter(w0, loss(w0), c='red', s=100)\n",
                "plt.xlabel('w')\n",
                "plt.ylabel('loss')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Recall that gradient descent is an iterative method. That means we will iteratively find new values of $w$ with the goal of incrementally reducing (i.e. minimizing) the loss function. We'll stop when we have determined that no lower value of the loss function can be found. \n",
                "\n",
                "The iterative approach will identify a new value, $w_{n+1}$, based on the previous value, $w_n$, as well as the loss function and its derivative. Namely:\n",
                "\n",
                "* $w_{n+1} = w_n \\, - \\, \\gamma \\cdot \\frac{d}{dw}\\mathrm{Loss}(w_n)$\n",
                "\n",
                "Note that the sign of the gradient, $\\frac{d}{dw}\\mathrm{Loss}(w_n)$, will determine in which direction we will take a step; while it's magnitude (or absolute value), will determine how large of a step to take. \n",
                "\n",
                "The term $\\gamma$ can be thought of as a way to scale how large the step should be. In machine learning this is called the __learning rate__ (see the Wikipedia entry on [gradient descent](https://en.wikipedia.org/wiki/Gradient_descent) for more info). The learning rate can be considered a hyperparameter, since it can affect how well (and how quickly) the model can be fit to the training data. \n",
                "\n",
                "Let's now step through the first iteration to find $w_{1} = w_0 \\, - \\, \\gamma \\cdot \\frac{d}{dw}\\mathrm{Loss}(w_0)$."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# define gamma, i.e. a 'learning rate' hyperparameter\n",
                "lr = 1e-1\n",
                "\n",
                "# derivative of the loss function (double check this yourself by hand)\n",
                "def dloss_dx(x):\n",
                "    return 4 * x - 8   #return x - 4\n",
                "\n",
                "# find w_{n+1} then plot and print it\n",
                "w1 = w0 - lr * dloss_dx(w0)\n",
                "plt.plot(ws, loss(ws))\n",
                "plt.scatter(w0, loss(w0), c='red', s=100, alpha=0.5)\n",
                "plt.scatter(w1, loss(w1), c='red', s=100)\n",
                "plt.xlabel('w')\n",
                "plt.ylabel('loss')\n",
                "plt.show() \n",
                "print(f\"w1 = {w1:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Notice that the new value of $w$, $w_1$, results in a value of the loss function that is lower, which is what we're after. \n",
                "\n",
                "Let's now step through one more iteration to find $w_{2} = w_1 \\, - \\, \\gamma \\cdot \\frac{d}{dw}\\mathrm{Loss}(w_1)$."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# find next w_{n+1} then plot and print\n",
                "w2 = w1 - lr * dloss_dx(w1)\n",
                "plt.plot(ws, loss(ws))\n",
                "plt.scatter(w0, loss(w0), c='red', s=100, alpha=0.25)\n",
                "plt.scatter(w1, loss(w1), c='red', s=100, alpha=0.5)\n",
                "plt.scatter(w2, loss(w2), c='red', s=100)\n",
                "plt.xlabel('w')\n",
                "plt.ylabel('loss')\n",
                "plt.show() \n",
                "print(f\"w2 = {w2:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Again, the $w$ yields an even smaller value of the loss function. Let's now find the next one:\n",
                "* $w_{3} = w_2 \\, - \\, \\gamma \\cdot \\frac{d}{dw}\\mathrm{Loss}(w_2)$."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# find next w_{n+1} then plot and print\n",
                "w3 = w2 - lr * dloss_dx(w2)\n",
                "plt.plot(ws, loss(ws))\n",
                "plt.scatter(w0, loss(w0), c='red', s=100, alpha=0.1)\n",
                "plt.scatter(w1, loss(w1), c='red', s=100, alpha=0.25)\n",
                "plt.scatter(w2, loss(w2), c='red', s=100, alpha=0.5)\n",
                "plt.scatter(w3, loss(w3), c='red', s=100)\n",
                "plt.xlabel('w')\n",
                "plt.ylabel('loss')\n",
                "plt.show() \n",
                "print(f\"w3 = {w3:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "One more:\n",
                "* $w_{4} = w_3 \\, - \\, \\gamma \\cdot \\frac{d}{dw}\\mathrm{Loss}(w_3)$"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# find next w_{n+1} then plot and print\n",
                "w4 = w3 - lr * dloss_dx(w3)\n",
                "plt.plot(ws, loss(ws))\n",
                "plt.scatter(w0, loss(w0), c='red', s=100, alpha=0.05)\n",
                "plt.scatter(w1, loss(w1), c='red', s=100, alpha=0.1)\n",
                "plt.scatter(w2, loss(w2), c='red', s=100, alpha=0.25)\n",
                "plt.scatter(w3, loss(w3), c='red', s=100, alpha=0.5)\n",
                "plt.scatter(w4, loss(w4), c='red', s=100)\n",
                "plt.xlabel('w')\n",
                "plt.ylabel('loss')\n",
                "plt.show() \n",
                "print(f\"w4 = {w4:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's now try iterating many, many times. However, let's also set an early-stopping criteria so that if $w$ is very close to value that minimizes the loss function, then we can go ahead and stop. Notice that as $w$ gets closer to the ideal value, it takes smaller and smaller steps each time. We'll use this fact to make a rule that says that if the absolute value of $w_{n+1} - w_n$ is less than some threshold or tolerance, then go ahead and stop iterating. \n",
                "\n",
                "__TIP:__ Try running the following cell once. Then, try running it again for different starting values, $w_0$ and different values of the learning rate, $lr$. Observe how many more (or fewer) iterations are needed for different values. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "lr = 1e-1\n",
                "max_iterations = 30\n",
                "tolerance = 1e-4\n",
                "w_0 = -9\n",
                "points = [(w_0, loss(w_0))]\n",
                "w_n = w_0\n",
                "w_np1 = None\n",
                "\n",
                "for i in range(max_iterations):\n",
                "    w_np1 = w_n - lr * dloss_dx(w_n)\n",
                "    print(f\"(iteration: {i:2d}) w_n+1 = {w_np1:.6f}, change from w_n = {w_np1 - w_n:.6f}\")\n",
                "    if abs(w_np1 - w_n) < tolerance:\n",
                "        print(f\"*** done (since {abs(w_np1 - w_n):.6f} < {tolerance:.6f}) ***\")\n",
                "        break\n",
                "    w_n = w_np1\n",
                "    points.append((w_n, loss(w_n)))\n",
                "\n",
                "plt.plot(ws, loss(ws))\n",
                "for i, pt in enumerate(points):\n",
                "    plt.scatter(pt[0], pt[1], c='red', s=100, alpha=((i+1)/(len(points)))**(3/4))\n",
                "plt.xlabel('w')\n",
                "plt.ylabel('loss')\n",
                "plt.show() \n",
                "print(f\"w_n = {w_n:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2. A (slightly) More Interesting Function\n",
                "\n",
                "Now, suppose that we have a new model and new loss function. The loss (as a function of the parameter, $w$) is shown below. \n",
                "\n",
                "What is different about this loss function? And, what considerations do you think we'll need to make when attempting to find a value of $w$ to minimize this loss function? \n",
                "\n",
                "Think about those questions as we run through a few iterations of gradient descent. We'll use a starting value of $w_0 = -27$ this time. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def loss(w):\n",
                "    return np.power(0.5*w - 2, 4) - np.square(7*w - 3) + 8\n",
                "\n",
                "w0 = -27 \n",
                "\n",
                "ws = np.arange(-28, 40, 0.5)\n",
                "plt.plot(ws, loss(ws))\n",
                "plt.scatter(w0, loss(w0), c='r', s=100)\n",
                "plt.xlabel('w')\n",
                "plt.ylabel('loss')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "As we did before, let's now find $w_1$."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def dloss_dx(x):\n",
                "    res = 2*np.power(0.5*x - 2, 3) - 14*(7*x - 3)\n",
                "    return res\n",
                "\n",
                "lr = 1e-3\n",
                "\n",
                "# find w_{n+1} then plot and print it\n",
                "w1 = w0 - lr * dloss_dx(w0)\n",
                "plt.plot(ws, loss(ws))\n",
                "plt.scatter(w0, loss(w0), c='red', s=100, alpha=0.5)\n",
                "plt.scatter(w1, loss(w1), c='red', s=100)\n",
                "plt.xlabel('w')\n",
                "plt.ylabel('loss')\n",
                "plt.show() \n",
                "print(f\"w1 = {w1:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "That was a step in the right direction, but where will $w$ stop? Let's run many iterations again, and again use our early-stopping criteria. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "lr = 1e-3\n",
                "max_iterations = 30\n",
                "tolerance = 1e-2\n",
                "\n",
                "w_0 = -27 \n",
                "points = [(w_0, loss(w_0))]\n",
                "\n",
                "w_n = w_0\n",
                "w_np1 = None\n",
                "\n",
                "for i in range(max_iterations):\n",
                "    w_np1 = w_n - lr * dloss_dx(w_n)\n",
                "    if i % 5 == 0:\n",
                "        print(f\"w_n+1 = {w_np1:.8f}, change from w_n = {w_np1 - w_n:.8f}\")\n",
                "    if abs(w_np1 - w_n) < tolerance:\n",
                "        print(f\"*** done (since {abs(w_np1 - w_n):.8f} < {tolerance:.8f}) ***\")\n",
                "        break\n",
                "    w_n = w_np1\n",
                "    points.append((w_n, loss(w_n)))\n",
                "\n",
                "plt.plot(ws, loss(ws))\n",
                "for i, pt in enumerate(points):\n",
                "    plt.scatter(pt[0], pt[1], c='red', s=100, alpha=((i+1)/(len(points)))**(1/2))\n",
                "plt.xlabel('w')\n",
                "plt.ylabel('loss')\n",
                "plt.show() \n",
                "print(f\"w_n = {w_n:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "What we see above is that $w$ is sensitive to the initial value it is given. For this loss function, any value initial value, $w_0$, that is less than approximately zero will likely find the local minima that is located at around $w = -13.75$, which is not the global minima we want at approximately $w = 25$.\n",
                "\n",
                "__TIP:__ Go to the wikipedia article on [Gradient Descent](https://en.wikipedia.org/wiki/Gradient_descent) to see an animation of gradient descent over two dimensions with many local minima and for various starting points. \n",
                "\n",
                "One way to resolve this is to try training/fitting our model several times, each time with a different initial value of $w_0$. Sometimes the value of $w_0$ will lead to the global minima, and sometimes not. We would then know which is better by looking at the values of the loss function. \n",
                "\n",
                "__TIP:__ Try rerunning the cell above with a different starting value, $w_0$, and/or with a different learning rate. See if/how it is possible to find the global minimum. \n",
                "\n",
                "Fortunately, there are variations of gradient descent that can also help to avoid us 'landing in' a local minima. Methods such as gradient descent with momentum, AdaM, and others are made specifically to do this. \n",
                "\n",
                "We'll also see that when we are training models with large sets of data, we will use a different subset of the training data each time. This means that the loss function can change slightly also. Specifically, the minima will be in a different location each time we use a different subset of the training data. \n",
                "\n",
                "Despite these techniques it can still be very challenging to find optimal parameter values when training neural networks. "
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.9.12 ('base')",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.3"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "bb3398f4b21c7b026dd5874af3f954bf25f1e8ff81e25d82a94abcbbaacf760b"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
