{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlokidrxZZEw"
      },
      "source": [
        "# Learning Embeddings with Continuous Bag of Words (CBOW)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sgeinitz/cs39aa_notebooks/blob/main/misc/embeddings_w_frankenstein.ipynb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMWe7B7CZZEy"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJjHmTD0ZZEz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from argparse import Namespace\n",
        "from collections import Counter\n",
        "import json\n",
        "import re\n",
        "import string\n",
        "import tqdm\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib \n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZO0e8D1ZZE0"
      },
      "source": [
        "## Data Vectorization classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXjj0DdJZZE0"
      },
      "source": [
        "### The Vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sfoJnJBaZZE0"
      },
      "outputs": [],
      "source": [
        "class Vocabulary(object):\n",
        "    \"\"\"Class to process text and extract vocabulary for mapping\"\"\"\n",
        "\n",
        "    def __init__(self, token_to_idx=None, mask_token=\"<MASK>\", add_unk=True, unk_token=\"<UNK>\"):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            token_to_idx (dict): a pre-existing map of tokens to indices\n",
        "            mask_token (str): the MASK token to add into the Vocabulary; indicates\n",
        "                a position that will not be used in updating the model's parameters\n",
        "            add_unk (bool): a flag that indicates whether to add the UNK token\n",
        "            unk_token (str): the UNK token to add into the Vocabulary\n",
        "            \n",
        "        \"\"\"\n",
        "\n",
        "        if token_to_idx is None:\n",
        "            token_to_idx = {}\n",
        "        self._token_to_idx = token_to_idx\n",
        "\n",
        "        self._idx_to_token = {idx: token \n",
        "                              for token, idx in self._token_to_idx.items()}\n",
        "        \n",
        "        self._add_unk = add_unk\n",
        "        self._unk_token = unk_token\n",
        "        self._mask_token = mask_token\n",
        "        \n",
        "        self.mask_index = self.add_token(self._mask_token)\n",
        "        self.unk_index = -1\n",
        "        if add_unk:\n",
        "            self.unk_index = self.add_token(unk_token) \n",
        "        \n",
        "    def to_serializable(self):\n",
        "        \"\"\" returns a dictionary that can be serialized \"\"\"\n",
        "        return {'token_to_idx': self._token_to_idx, \n",
        "                'add_unk': self._add_unk, \n",
        "                'unk_token': self._unk_token, \n",
        "                'mask_token': self._mask_token}\n",
        "\n",
        "    @classmethod\n",
        "    def from_serializable(cls, contents):\n",
        "        \"\"\" instantiates the Vocabulary from a serialized dictionary \"\"\"\n",
        "        return cls(**contents)\n",
        "\n",
        "    def add_token(self, token):\n",
        "        \"\"\"Update mapping dicts based on the token.\n",
        "\n",
        "        Args:\n",
        "            token (str): the item to add into the Vocabulary\n",
        "        Returns:\n",
        "            index (int): the integer corresponding to the token\n",
        "        \"\"\"\n",
        "        if token in self._token_to_idx:\n",
        "            index = self._token_to_idx[token]\n",
        "        else:\n",
        "            index = len(self._token_to_idx)\n",
        "            self._token_to_idx[token] = index\n",
        "            self._idx_to_token[index] = token\n",
        "        return index\n",
        "            \n",
        "    def add_many(self, tokens):\n",
        "        \"\"\"Add a list of tokens into the Vocabulary\n",
        "        \n",
        "        Args:\n",
        "            tokens (list): a list of string tokens\n",
        "        Returns:\n",
        "            indices (list): a list of indices corresponding to the tokens\n",
        "        \"\"\"\n",
        "        return [self.add_token(token) for token in tokens]\n",
        "\n",
        "    def lookup_token(self, token):\n",
        "        \"\"\"Retrieve the index associated with the token \n",
        "          or the UNK index if token isn't present.\n",
        "        \n",
        "        Args:\n",
        "            token (str): the token to look up \n",
        "        Returns:\n",
        "            index (int): the index corresponding to the token\n",
        "        Notes:\n",
        "            `unk_index` needs to be >=0 (having been added into the Vocabulary) \n",
        "              for the UNK functionality \n",
        "        \"\"\"\n",
        "        if self.unk_index >= 0:\n",
        "            return self._token_to_idx.get(token, self.unk_index)\n",
        "        else:\n",
        "            return self._token_to_idx[token]\n",
        "\n",
        "    def lookup_index(self, index):\n",
        "        \"\"\"Return the token associated with the index\n",
        "        \n",
        "        Args: \n",
        "            index (int): the index to look up\n",
        "        Returns:\n",
        "            token (str): the token corresponding to the index\n",
        "        Raises:\n",
        "            KeyError: if the index is not in the Vocabulary\n",
        "        \"\"\"\n",
        "        if index not in self._idx_to_token:\n",
        "            raise KeyError(\"the index (%d) is not in the Vocabulary\" % index)\n",
        "        return self._idx_to_token[index]\n",
        "\n",
        "    def __str__(self):\n",
        "        return \"<Vocabulary(size=%d)>\" % len(self)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._token_to_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b_Hp2o_pZZE1"
      },
      "outputs": [],
      "source": [
        "class CBOWVectorizer(object):\n",
        "    \"\"\" The Vectorizer which coordinates the Vocabularies and puts them to use\"\"\"    \n",
        "    def __init__(self, cbow_vocab):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            cbow_vocab (Vocabulary): maps words to integers\n",
        "        \"\"\"\n",
        "        self.cbow_vocab = cbow_vocab\n",
        "\n",
        "    def vectorize(self, context, vector_length=-1):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            context (str): the string of words separated by a space\n",
        "            vector_length (int): an argument for forcing the length of index vector\n",
        "        \"\"\"\n",
        "\n",
        "        indices = [self.cbow_vocab.lookup_token(token) for token in context.split(' ')]\n",
        "        if vector_length < 0:\n",
        "            vector_length = len(indices)\n",
        "\n",
        "        out_vector = np.zeros(vector_length, dtype=np.int64)\n",
        "        out_vector[:len(indices)] = indices\n",
        "        out_vector[len(indices):] = self.cbow_vocab.mask_index\n",
        "\n",
        "        return out_vector\n",
        "    \n",
        "    @classmethod\n",
        "    def from_dataframe(cls, cbow_df):\n",
        "        \"\"\"Instantiate the vectorizer from the dataset dataframe\n",
        "        \n",
        "        Args:\n",
        "            cbow_df (pandas.DataFrame): the target dataset\n",
        "        Returns:\n",
        "            an instance of the CBOWVectorizer\n",
        "        \"\"\"\n",
        "        cbow_vocab = Vocabulary()\n",
        "        for index, row in cbow_df.iterrows():\n",
        "            for token in row.context.split(' '):\n",
        "                cbow_vocab.add_token(token)\n",
        "            cbow_vocab.add_token(row.target)\n",
        "            \n",
        "        return cls(cbow_vocab)\n",
        "\n",
        "    @classmethod\n",
        "    def from_serializable(cls, contents):\n",
        "        cbow_vocab = \\\n",
        "            Vocabulary.from_serializable(contents['cbow_vocab'])\n",
        "        return cls(cbow_vocab=cbow_vocab)\n",
        "\n",
        "    def to_serializable(self):\n",
        "        return {'cbow_vocab': self.cbow_vocab.to_serializable()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guC5jH6BZZE2"
      },
      "source": [
        "### The Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pVL7egV5ZZE2"
      },
      "outputs": [],
      "source": [
        "class CBOWDataset(Dataset):\n",
        "    def __init__(self, cbow_df, vectorizer):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            cbow_df (pandas.DataFrame): the dataset\n",
        "            vectorizer (CBOWVectorizer): vectorizer instatiated from dataset\n",
        "        \"\"\"\n",
        "        self.cbow_df = cbow_df\n",
        "        self._vectorizer = vectorizer\n",
        "        \n",
        "        measure_len = lambda context: len(context.split(\" \"))\n",
        "        self._max_seq_length = max(map(measure_len, cbow_df.context))\n",
        "        \n",
        "        self.train_df = self.cbow_df[self.cbow_df.split=='train']\n",
        "        self.train_size = len(self.train_df)\n",
        "\n",
        "        self.val_df = self.cbow_df[self.cbow_df.split=='val']\n",
        "        self.validation_size = len(self.val_df)\n",
        "\n",
        "        self.test_df = self.cbow_df[self.cbow_df.split=='test']\n",
        "        self.test_size = len(self.test_df)\n",
        "\n",
        "        self._lookup_dict = {'train': (self.train_df, self.train_size),\n",
        "                             'val': (self.val_df, self.validation_size),\n",
        "                             'test': (self.test_df, self.test_size)}\n",
        "\n",
        "        self.set_split('train')\n",
        "\n",
        "    @classmethod\n",
        "    def load_dataset_and_make_vectorizer(cls, cbow_csv):\n",
        "        \"\"\"Load dataset and make a new vectorizer from scratch\n",
        "        \n",
        "        Args:\n",
        "            cbow_csv (str): location of the dataset\n",
        "        Returns:\n",
        "            an instance of CBOWDataset\n",
        "        \"\"\"\n",
        "        cbow_df = pd.read_csv(cbow_csv)\n",
        "        train_cbow_df = cbow_df[cbow_df.split=='train']\n",
        "        return cls(cbow_df, CBOWVectorizer.from_dataframe(train_cbow_df))\n",
        "\n",
        "    @classmethod\n",
        "    def load_dataset_and_load_vectorizer(cls, cbow_csv, vectorizer_filepath):\n",
        "        \"\"\"Load dataset and the corresponding vectorizer. \n",
        "        Used in the case in the vectorizer has been cached for re-use\n",
        "        \n",
        "        Args:\n",
        "            cbow_csv (str): location of the dataset\n",
        "            vectorizer_filepath (str): location of the saved vectorizer\n",
        "        Returns:\n",
        "            an instance of CBOWDataset\n",
        "        \"\"\"\n",
        "        cbow_df = pd.read_csv(cbow_csv)\n",
        "        vectorizer = cls.load_vectorizer_only(vectorizer_filepath)\n",
        "        return cls(cbow_df, vectorizer)\n",
        "\n",
        "    @staticmethod\n",
        "    def load_vectorizer_only(vectorizer_filepath):\n",
        "        \"\"\"a static method for loading the vectorizer from file\n",
        "        \n",
        "        Args:\n",
        "            vectorizer_filepath (str): the location of the serialized vectorizer\n",
        "        Returns:\n",
        "            an instance of CBOWVectorizer\n",
        "        \"\"\"\n",
        "        with open(vectorizer_filepath) as fp:\n",
        "            return CBOWVectorizer.from_serializable(json.load(fp))\n",
        "\n",
        "    def save_vectorizer(self, vectorizer_filepath):\n",
        "        \"\"\"saves the vectorizer to disk using json\n",
        "        \n",
        "        Args:\n",
        "            vectorizer_filepath (str): the location to save the vectorizer\n",
        "        \"\"\"\n",
        "        with open(vectorizer_filepath, \"w\") as fp:\n",
        "            json.dump(self._vectorizer.to_serializable(), fp)\n",
        "\n",
        "    def get_vectorizer(self):\n",
        "        \"\"\" returns the vectorizer \"\"\"\n",
        "        return self._vectorizer\n",
        "        \n",
        "    def set_split(self, split=\"train\"):\n",
        "        \"\"\" selects the splits in the dataset using a column in the dataframe \"\"\"\n",
        "        self._target_split = split\n",
        "        self._target_df, self._target_size = self._lookup_dict[split]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self._target_size\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"the primary entry point method for PyTorch datasets\n",
        "        \n",
        "        Args:\n",
        "            index (int): the index to the data point \n",
        "        Returns:\n",
        "            a dictionary holding the data point's features (x_data) and label (y_target)\n",
        "        \"\"\"\n",
        "        row = self._target_df.iloc[index]\n",
        "\n",
        "        context_vector = \\\n",
        "            self._vectorizer.vectorize(row.context, self._max_seq_length)\n",
        "        target_index = self._vectorizer.cbow_vocab.lookup_token(row.target)\n",
        "\n",
        "        return {'x_data': context_vector,\n",
        "                'y_target': target_index}\n",
        "\n",
        "    def get_num_batches(self, batch_size):\n",
        "        \"\"\"Given a batch size, return the number of batches in the dataset\n",
        "        \n",
        "        Args:\n",
        "            batch_size (int)\n",
        "        Returns:\n",
        "            number of batches in the dataset\n",
        "        \"\"\"\n",
        "        return len(self) // batch_size\n",
        "    \n",
        "def generate_batches(dataset, batch_size, shuffle=True,\n",
        "                     drop_last=True, device=\"cpu\"): \n",
        "    \"\"\"\n",
        "    A generator function which wraps the PyTorch DataLoader. It will \n",
        "      ensure each tensor is on the write device location.\n",
        "    \"\"\"\n",
        "    dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\n",
        "                            shuffle=shuffle, drop_last=drop_last)\n",
        "\n",
        "    for data_dict in dataloader:\n",
        "        out_data_dict = {}\n",
        "        for name, tensor in data_dict.items():\n",
        "            out_data_dict[name] = data_dict[name].to(device)\n",
        "        yield out_data_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrtrMFQkZZE2"
      },
      "source": [
        "## The Model: Continuous-bag-of-Words Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ImZBw6XZZE2"
      },
      "outputs": [],
      "source": [
        "class CBOWClassifier(nn.Module): # Simplified cbow Model\n",
        "    def __init__(self, vocabulary_size, embedding_size, padding_idx=0):\n",
        "        \n",
        "        super(CBOWClassifier, self).__init__()\n",
        "        \n",
        "        self.embedding =  nn.Embedding(num_embeddings=vocabulary_size, \n",
        "                                       embedding_dim=embedding_size,\n",
        "                                       padding_idx=padding_idx)\n",
        "\n",
        "\n",
        "\n",
        "        # use these when we keep the embedding tensors separate, and flatten them into a rank-1 tensor that is 6x longer \n",
        "        self.bn = nn.BatchNorm1d(num_features=embedding_size * 6)        \n",
        "        self.fc1 = nn.Linear(in_features=embedding_size * 6, out_features=vocabulary_size)\n",
        "\n",
        "        # use these when we sum together the embedding tensors from the previous layer\n",
        "        #self.bn = nn.BatchNorm1d(num_features=embedding_size * 6)        \n",
        "        #self.fc1 = nn.Linear(in_features=embedding_size, out_features=vocabulary_size)\n",
        "\n",
        "    def forward(self, x_in, apply_dropout=False, apply_softmax=False):\n",
        "\n",
        "        # keep all 6 embeddings separate but flatten them into a lower-rank tensor\n",
        "        x_interm = torch.flatten(self.embedding(x_in.long()), start_dim=1)\n",
        "\n",
        "        # combine the 6 embeddings by takign their sum\n",
        "        #x_interm = self.embedding(x_in.long()).sum(dim=1)        \n",
        "        \n",
        "        if apply_dropout:\n",
        "            x_interm = F.dropout(x_interm, 0.6)\n",
        " \n",
        "        x_interm = F.relu(x_interm)\n",
        "        x_interm = self.bn(x_interm)\n",
        "               \n",
        "        y_out = self.fc1(x_interm)\n",
        "        \n",
        "        if apply_softmax:\n",
        "            y_out = F.softmax(y_out, dim=1)\n",
        "            \n",
        "        return y_out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3X_FTGHIZZE2"
      },
      "source": [
        "## Training Routine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0IDUJ07ZZE3"
      },
      "source": [
        "### Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VxbFFJo3ZZE3"
      },
      "outputs": [],
      "source": [
        "def make_train_state(args):\n",
        "    return {'stop_early': False,\n",
        "            'early_stopping_step': 0,\n",
        "            'early_stopping_best_val': 1e8,\n",
        "            'learning_rate': args.learning_rate,\n",
        "            'epoch_index': 0,\n",
        "            'train_loss': [],\n",
        "            'train_acc': [],\n",
        "            'val_loss': [],\n",
        "            'val_acc': [],\n",
        "            'test_loss': -1,\n",
        "            'test_acc': -1,\n",
        "            'model_filename': args.model_state_file}\n",
        "\n",
        "def update_train_state(args, model, train_state):\n",
        "    \"\"\"Handle the training state updates.\n",
        "\n",
        "    Components:\n",
        "     - Early Stopping: Prevent overfitting.\n",
        "     - Model Checkpoint: Model is saved if the model is better\n",
        "\n",
        "    :param args: main arguments\n",
        "    :param model: model to train\n",
        "    :param train_state: a dictionary representing the training state values\n",
        "    :returns:\n",
        "        a new train_state\n",
        "    \"\"\"\n",
        "\n",
        "    # Save one model at least\n",
        "    if train_state['epoch_index'] == 0:\n",
        "        torch.save(model.state_dict(), train_state['model_filename'])\n",
        "        train_state['stop_early'] = False\n",
        "\n",
        "    # Save model if performance improved\n",
        "    elif train_state['epoch_index'] >= 1:\n",
        "        loss_tm1, loss_t = train_state['val_loss'][-2:]\n",
        "\n",
        "        # If loss worsened\n",
        "        if loss_t >= train_state['early_stopping_best_val']:\n",
        "            # Update step\n",
        "            train_state['early_stopping_step'] += 1\n",
        "        # Loss decreased\n",
        "        else:\n",
        "            # Save the best model\n",
        "            if loss_t < train_state['early_stopping_best_val']:\n",
        "                torch.save(model.state_dict(), train_state['model_filename'])\n",
        "\n",
        "            # Reset early stopping step\n",
        "            train_state['early_stopping_step'] = 0\n",
        "\n",
        "        # Stop early ?\n",
        "        train_state['stop_early'] = \\\n",
        "            train_state['early_stopping_step'] >= args.early_stopping_criteria\n",
        "\n",
        "    return train_state\n",
        "\n",
        "def compute_accuracy(y_pred, y_target):\n",
        "    _, y_pred_indices = y_pred.max(dim=1)\n",
        "    n_correct = torch.eq(y_pred_indices, y_target).sum().item()\n",
        "    return n_correct / len(y_pred_indices) * 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-nTBzXGZZE3"
      },
      "source": [
        "#### general utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JX7xyD6FZZE3"
      },
      "outputs": [],
      "source": [
        "def set_seed_everywhere(seed, cuda):\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if cuda:\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "def handle_dirs(dirpath):\n",
        "    if not os.path.exists(dirpath):\n",
        "        os.makedirs(dirpath)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uO-ZJiYeZZE3"
      },
      "source": [
        "### Settings and some prep work"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vf6imrEJZZE4",
        "outputId": "2952dd41-5ea2-4323-ddb8-e22c4d06e436"
      },
      "outputs": [],
      "source": [
        "args = Namespace(\n",
        "    # Data and Path information\n",
        "    #cbow_csv=\"/Users/steve/icloud/MSU/Classes/CS39AA_2022fall/cs39aa_notebooks/data/frankenstein_with_splits.csv\",\n",
        "    cbow_csv=\"https://raw.githubusercontent.com/sgeinitz/CS39AA/main/data/frankenstein_with_splits.csv\",\n",
        "    vectorizer_file=\"vectorizer.json\",\n",
        "    model_state_file=\"model.pth\",\n",
        "    save_dir=\"/Users/steve/models/frankenstein_cbow\",\n",
        "    # Model hyper parameters\n",
        "    embedding_size=50,\n",
        "    # Training hyper parameters\n",
        "    seed=42,\n",
        "    num_epochs=6,\n",
        "    learning_rate=0.001,\n",
        "    batch_size=500,\n",
        "    early_stopping_criteria=5,\n",
        "    # Runtime options\n",
        "    cuda=False,\n",
        "    catch_keyboard_interrupt=True,\n",
        "    reload_from_files=False,\n",
        "    expand_filepaths_to_save_dir=True\n",
        ")\n",
        "\n",
        "if args.expand_filepaths_to_save_dir:\n",
        "    args.vectorizer_file = os.path.join(args.save_dir,\n",
        "                                        args.vectorizer_file)\n",
        "\n",
        "    args.model_state_file = os.path.join(args.save_dir,\n",
        "                                         args.model_state_file)\n",
        "    \n",
        "    print(\"Expanded filepaths: \")\n",
        "    print(\"\\t{}\".format(args.vectorizer_file))\n",
        "    print(\"\\t{}\".format(args.model_state_file))\n",
        "    \n",
        "\n",
        "# Check CUDA\n",
        "if not torch.cuda.is_available():\n",
        "    args.cuda = False\n",
        "\n",
        "args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
        "    \n",
        "print(\"Using CUDA: {}\".format(args.cuda))\n",
        "\n",
        "\n",
        "# Set seed for reproducibility\n",
        "set_seed_everywhere(args.seed, args.cuda)\n",
        "\n",
        "# handle dirs\n",
        "handle_dirs(args.save_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1AYZMUsZZE4"
      },
      "source": [
        "### Initializations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpYEl83YZZE5",
        "outputId": "c9a79ff1-4a39-4169-9a0c-1b45662e44b7"
      },
      "outputs": [],
      "source": [
        "if args.reload_from_files:\n",
        "    print(\"Loading dataset and loading vectorizer\")\n",
        "    dataset = CBOWDataset.load_dataset_and_load_vectorizer(args.cbow_csv,\n",
        "                                                           args.vectorizer_file)\n",
        "else:\n",
        "    print(\"Loading dataset and creating vectorizer\")\n",
        "    dataset = CBOWDataset.load_dataset_and_make_vectorizer(args.cbow_csv)\n",
        "    dataset.save_vectorizer(args.vectorizer_file)\n",
        "    \n",
        "vectorizer = dataset.get_vectorizer()\n",
        "\n",
        "classifier = CBOWClassifier(vocabulary_size=len(vectorizer.cbow_vocab), \n",
        "                            embedding_size=args.embedding_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0ae94WQZZE5",
        "outputId": "77f77285-487e-41e7-d06a-1072f5bcf39f"
      },
      "outputs": [],
      "source": [
        "len(vectorizer.cbow_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8At1Ns0ZZE5",
        "outputId": "a6f3d98c-d1fd-4ee0-edb7-a1d782a14907"
      },
      "outputs": [],
      "source": [
        "print(\"first observation x data: \", dataset[0]['x_data'])\n",
        "print(\"                y target: \", dataset[0]['y_target'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQsUsjLBZZE6",
        "outputId": "0f7dc1d9-e62c-49e0-81b7-de018f89499d"
      },
      "outputs": [],
      "source": [
        "# Look at the first 10 tokens in the vocabulary\n",
        "for i in range(10):\n",
        "    print(f\"vocab i = {i} is {vectorizer.cbow_vocab.lookup_index(i)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyoNAkHGZZE6",
        "outputId": "df60f3ec-ff9b-412f-e257-59d28d7a2340"
      },
      "outputs": [],
      "source": [
        "[vectorizer.cbow_vocab.lookup_index(i) for i in dataset[0]['x_data']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-aWUYAkVZZE6",
        "outputId": "2e857f7a-568f-4d08-ab9e-4a4bd38dffcc"
      },
      "outputs": [],
      "source": [
        "i = 0\n",
        "print(f\"obs[{i}] x data: {dataset[i]['x_data']}\")\n",
        "print(f\"       y target: {dataset[i]['y_target']}\")\n",
        "print(f\"To predict token: '{vectorizer.cbow_vocab.lookup_index(dataset[i]['y_target'])}' \\n\")\n",
        "print(f\"input tokens used are: \\n   {[vectorizer.cbow_vocab.lookup_index(j) for j in dataset[i]['x_data']]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddQto-3lZZE6",
        "outputId": "8048c32c-4e89-410b-9f1f-1b0b360862a0"
      },
      "outputs": [],
      "source": [
        "i = 44445\n",
        "print(f\"obs[{i}] x data: {dataset[i]['x_data']}\")\n",
        "print(f\"           y target: {dataset[i]['y_target']}\")\n",
        "print(f\"To predict token: '{vectorizer.cbow_vocab.lookup_index(dataset[i]['y_target'])}' \\n\")\n",
        "print(f\"input tokens used are: \\n   {[vectorizer.cbow_vocab.lookup_index(j) for j in dataset[i]['x_data']]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UB07Gzu0ZZE6",
        "outputId": "11eee562-2153-4359-d978-c1d6f007695a"
      },
      "outputs": [],
      "source": [
        "print(f\"Number of unique tokens in the vocabulary is: {len(vectorizer.cbow_vocab)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMpM1VW6ZZE6",
        "outputId": "144c51fa-dc04-4b73-9110-0549f77d81e9"
      },
      "outputs": [],
      "source": [
        "from torchsummary import summary\n",
        "# before running this, need to go into model and change the line:\n",
        "# x_embedded_sum = F.dropout(self.embedding(x_in).sum(dim=1), 0.3)       \n",
        "# to be the following line (since embeddings must be an int/long input):\n",
        "#  x_embedded_sum = F.dropout(self.embedding(x_in.long()).sum(dim=1), 0.3)\n",
        "summary(classifier, input_size=(1,6))#, device='cpu')\n",
        "\n",
        "#summary(classifier, torch.randint(1000, (1024,6)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KegMqP0ZZE7"
      },
      "source": [
        "### Training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "code_folding": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "21441c5cd817431d82a016e9786e8cd9",
            "00ba227326f346e8b98c51ee6d05e01f",
            "65e57d46202f4114b3e525c977bedd6e",
            "b484be9c0b16436f83aaf2ca963cad8c",
            "4120637f7153488fbc43e8b5202573f8",
            "6595d9675c4d46899cf8a5e5cefbdf21",
            "d7bc4b293fe248efa48025472bf3d359",
            "4c3bd07439e6437591c6b5091c9c8e0e",
            "adc35ef77ca544fe8dbbf4c4e55ee937",
            "d0946e4a05314f9eba0c9bfdd0ca3671",
            "40245d3d23af46f3be8d0d2aebd908b3",
            "a23a795837e74365a35f241ece6ee856",
            "aa817f7466ce440694ec0a8c7f1d6d38",
            "68dc441427fb4b0d870417a2a600d39b",
            "8ded9d634bc548a790cb707c30234ebb",
            "c04a8b56bfd54bffa51f1f0366cb0069",
            "56b18987e1ca4092b65459ac1d1e0739",
            "f5fe46da9bd4485886dfb88536d337c9",
            "6e1b376c05a145f6884e176a8fb78f79",
            "1d3ae14466734acabc7f19c46016526f",
            "6b28aa01758d4d0f83189e0cf9311554",
            "a68e5545489447bbb44e2ef989b2e076",
            "451b34e0d9da47728514d2cc9a779802",
            "49db9eac1d094b7eb467742f556dceeb",
            "6714814012364f13a69b2c7df5d41506",
            "f1a4f44da5d845f08086b69d4645741c",
            "0cd2842f1dfb4f08a143b35d866d19b3",
            "7c16919376604f86bfb89675549deb5d",
            "4e63411a3aff410eb3d1654008296cd8",
            "3932c0ef68fb488ab1d0f434e88384f0",
            "c4af50d8e8a34aa3a1ec0c1cf45e10da",
            "2f3c745809de431a9c13386ae8246c0a",
            "532aee68a57b4a34b003df862bceac8e"
          ]
        },
        "id": "xyGzlSG8ZZE7",
        "outputId": "efe02490-9e0f-4207-ec78-40c8a6e3732f"
      },
      "outputs": [],
      "source": [
        "classifier = classifier.to(args.device)\n",
        "    \n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(classifier.parameters(), lr=args.learning_rate)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n",
        "                                                 mode='min', factor=0.5,\n",
        "                                                 patience=1)\n",
        "train_state = make_train_state(args)\n",
        "\n",
        "epoch_bar = tqdm.notebook.tqdm(desc='training routine', \n",
        "                          total=args.num_epochs,\n",
        "                          position=0)\n",
        "\n",
        "dataset.set_split('train')\n",
        "train_bar = tqdm.notebook.tqdm(desc='split=train',\n",
        "                          total=dataset.get_num_batches(args.batch_size), \n",
        "                          position=1, \n",
        "                          leave=True)\n",
        "dataset.set_split('val')\n",
        "val_bar = tqdm.notebook.tqdm(desc='split=val',\n",
        "                        total=dataset.get_num_batches(args.batch_size), \n",
        "                        position=1, \n",
        "                        leave=True)\n",
        "\n",
        "losses = {'train':[], 'val':[]}\n",
        "\n",
        "try:\n",
        "    for epoch_index in range(args.num_epochs):\n",
        "        train_state['epoch_index'] = epoch_index\n",
        "\n",
        "        # Iterate over training dataset\n",
        "\n",
        "        # setup: batch generator, set loss and acc to 0, set train mode on\n",
        "\n",
        "        dataset.set_split('train')\n",
        "        batch_generator = generate_batches(dataset, \n",
        "                                           batch_size=args.batch_size, \n",
        "                                           device=args.device)\n",
        "        running_loss = 0.0\n",
        "        running_acc = 0.0\n",
        "        classifier.train()\n",
        "\n",
        "        for batch_index, batch_dict in enumerate(batch_generator):\n",
        "            # the training routine is these 5 steps:\n",
        "\n",
        "            # --------------------------------------\n",
        "            # step 1. zero the gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # step 2. compute the output\n",
        "            y_pred = classifier.forward(x_in=batch_dict['x_data'], apply_dropout=True)\n",
        "\n",
        "            # step 3. compute the loss\n",
        "            loss = loss_func(y_pred, batch_dict['y_target'])\n",
        "            loss_t = loss.item()\n",
        "            losses['train'].append(loss_t)\n",
        "            running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
        "\n",
        "            # step 4. use loss to produce gradients\n",
        "            loss.backward()\n",
        "\n",
        "            # step 5. use optimizer to take gradient step\n",
        "            optimizer.step()\n",
        "            # -----------------------------------------\n",
        "            # compute the accuracy\n",
        "            acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\n",
        "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "\n",
        "            # update bar\n",
        "            train_bar.set_postfix(loss=running_loss, acc=running_acc, \n",
        "                            epoch=epoch_index)\n",
        "            train_bar.update()\n",
        "\n",
        "        train_state['train_loss'].append(running_loss)\n",
        "        train_state['train_acc'].append(running_acc)\n",
        "\n",
        "        # Iterate over val dataset\n",
        "\n",
        "        # setup: batch generator, set loss and acc to 0; set eval mode on\n",
        "        dataset.set_split('val')\n",
        "        batch_generator = generate_batches(dataset, \n",
        "                                           batch_size=args.batch_size, \n",
        "                                           device=args.device)\n",
        "        running_loss = 0.\n",
        "        running_acc = 0.\n",
        "        classifier.eval()\n",
        "\n",
        "        for batch_index, batch_dict in enumerate(batch_generator):\n",
        "\n",
        "            # compute the output\n",
        "            y_pred =  classifier.forward(x_in=batch_dict['x_data'], apply_dropout=False)\n",
        "\n",
        "            # step 3. compute the loss\n",
        "            loss = loss_func(y_pred, batch_dict['y_target'])\n",
        "            loss_t = loss.item()\n",
        "            losses['val'].append(loss_t)            \n",
        "            running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
        "\n",
        "            # compute the accuracy\n",
        "            acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\n",
        "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "            val_bar.set_postfix(loss=running_loss, acc=running_acc, \n",
        "                            epoch=epoch_index)\n",
        "            val_bar.update()\n",
        "\n",
        "        train_state['val_loss'].append(running_loss)\n",
        "        train_state['val_acc'].append(running_acc)\n",
        "\n",
        "        train_state = update_train_state(args=args, model=classifier,\n",
        "                                         train_state=train_state)\n",
        "\n",
        "        scheduler.step(train_state['val_loss'][-1])\n",
        "\n",
        "        if train_state['stop_early']:\n",
        "            break\n",
        "\n",
        "        train_bar.n = 0\n",
        "        val_bar.n = 0\n",
        "        epoch_bar.update()\n",
        "except KeyboardInterrupt:\n",
        "    print(\"Exiting loop\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "HqJCmecJZZE7",
        "outputId": "bdab9da3-eaaf-41ad-8548-a22541443d50"
      },
      "outputs": [],
      "source": [
        "matplotlib.rc('figure', figsize=(15,4))\n",
        "val_ticks = [(i+1)*len(losses['train'])/len(losses['val']) for i in range(len(losses['val']))]\n",
        "plt.plot(range(len(losses['train'])), losses['train'], c='blue', lw=0.75)\n",
        "plt.plot(val_ticks, losses['val'], c='orange', lw=0.75)\n",
        "for i in range(args.num_epochs):\n",
        "    plt.axvline(x=i*len(losses['train'])/args.num_epochs, c='black', lw=0.25, alpha=0.5)\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch and Batch')\n",
        "plt.legend(('Train','Validation'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOaaDPm2ZZE7",
        "outputId": "00c9e5b3-8983-4d8a-f027-7b08b17122b2"
      },
      "outputs": [],
      "source": [
        "y_pred.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qM9BSHy0ZZE7",
        "outputId": "676fbcab-f40a-4103-aa54-6b26a3f26b8d"
      },
      "outputs": [],
      "source": [
        "batch_dict['x_data'].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wIxI-dYuZZE8"
      },
      "outputs": [],
      "source": [
        "# compute the loss & accuracy on the test set using the best available model\n",
        "\n",
        "classifier.load_state_dict(torch.load(train_state['model_filename']))\n",
        "classifier = classifier.to(args.device)\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "\n",
        "dataset.set_split('test')\n",
        "batch_generator = generate_batches(dataset, \n",
        "                                   batch_size=args.batch_size, \n",
        "                                   device=args.device)\n",
        "running_loss = 0.\n",
        "running_acc = 0.\n",
        "classifier.eval()\n",
        "\n",
        "for batch_index, batch_dict in enumerate(batch_generator):\n",
        "    # compute the output\n",
        "    y_pred =  classifier(x_in=batch_dict['x_data'])\n",
        "    \n",
        "    # compute the loss\n",
        "    loss = loss_func(y_pred, batch_dict['y_target'])\n",
        "    loss_t = loss.item()\n",
        "    running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
        "\n",
        "    # compute the accuracy\n",
        "    acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\n",
        "    running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "\n",
        "train_state['test_loss'] = running_loss\n",
        "train_state['test_acc'] = running_acc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTT16T7kZZE8",
        "outputId": "c28b8a14-05dd-44d0-b8f8-c4bdaf5c0350"
      },
      "outputs": [],
      "source": [
        "print(\"Test loss: {};\".format(train_state['test_loss']))\n",
        "print(\"Test Accuracy: {}\".format(train_state['test_acc']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJKS7JYbZZE8"
      },
      "source": [
        "### Trained Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rp9FD0_aZZE8"
      },
      "outputs": [],
      "source": [
        "def pretty_print(results):\n",
        "    \"\"\"\n",
        "    Pretty print embedding results.\n",
        "    \"\"\"\n",
        "    for item in results:\n",
        "        print (f\"dist = {item[1]:.2f} for word: {item[0]}\")\n",
        "\n",
        "def get_closest(target_word, word_to_idx, embeddings, n=5):\n",
        "    \"\"\"\n",
        "    Get the n closest\n",
        "    words to your word.\n",
        "    \"\"\"\n",
        "\n",
        "    # Calculate distances to all other words\n",
        "    \n",
        "    word_embedding = embeddings[word_to_idx[target_word.lower()]]\n",
        "    distances = []\n",
        "    for word, index in word_to_idx.items():\n",
        "        if word == \"<MASK>\" or word == target_word:\n",
        "            continue\n",
        "        distances.append((word, torch.dist(word_embedding, embeddings[index])))\n",
        "    \n",
        "    results = sorted(distances, key=lambda x: x[1])[1:n+2]\n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_IQLxSdZZE9",
        "outputId": "722e23a4-d1a4-4b19-986e-523765ad7ded"
      },
      "outputs": [],
      "source": [
        "word = input('Enter a word: ')\n",
        "embeddings = classifier.embedding.weight.data\n",
        "word_to_idx = vectorizer.cbow_vocab._token_to_idx\n",
        "pretty_print(get_closest(word, word_to_idx, embeddings, n=5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1G9m-0VZZE9",
        "outputId": "5859c67b-f05f-4292-d9ad-ec83f562ccd5"
      },
      "outputs": [],
      "source": [
        "embeddings.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRX3I8gJZZE9",
        "outputId": "f7b0473f-6665-4adb-e44c-1ab6ec44d8ae",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "#target_words = ['frankenstein', 'monster', 'science', 'sickness', 'lonely', 'eye']\n",
        "\n",
        "#target_words = ['frankenstein', 'monster', 'mad', 'different', 'man']\n",
        "\n",
        "target_words = ['frankenstein', 'monster', 'science', 'sickness', 'lonely']\n",
        "embeddings = classifier.embedding.weight.data\n",
        "word_to_idx = vectorizer.cbow_vocab._token_to_idx\n",
        "\n",
        "for target_word in target_words: \n",
        "    print(f\"======={target_word}=======\")\n",
        "    if target_word not in word_to_idx:\n",
        "        print(\"Not in vocabulary\")\n",
        "        continue\n",
        "    pretty_print(get_closest(target_word, word_to_idx, embeddings, n=5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's now try to visualize the embeddings by reducing the 50-dimensional word vectors to 2-dimensions each. The approach we'll use is called t-stochastic neighbor embedding, although somethign like PCA (principle components analysis) could be used as well. See this Kaggle notebook that also performs data visualization on embeddings, but uses movie data, and therefore has a greater range of visualizations that can be interesting. \n",
        "* https://www.kaggle.com/code/colinmorris/visualizing-embeddings-with-t-sne/notebook "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwKeaggoZZE9",
        "outputId": "97a6ad3e-14ad-42e7-f632-e07db4c0d0f0"
      },
      "outputs": [],
      "source": [
        "embs = classifier.embedding.weight.detach().numpy()\n",
        "embs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwJkPYH4cjBl",
        "outputId": "981dd5cc-3662-4a7d-b6e9-8eb3de0a3676"
      },
      "outputs": [],
      "source": [
        "emb_words = list(vectorizer.cbow_vocab._idx_to_token.values())\n",
        "emb_words[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_aeV5j2mZZE9",
        "outputId": "c9045983-544f-433b-a36a-3e4074727b8f"
      },
      "outputs": [],
      "source": [
        "from sklearn.manifold import TSNE\n",
        "\n",
        "embs_red = TSNE(n_components=2, learning_rate='auto', init='pca', perplexity=15).fit_transform(embs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nUsd16a6bV66"
      },
      "outputs": [],
      "source": [
        "df_embs = pd.DataFrame({'word':emb_words, 'x':embs_red[:,0], 'y':embs_red[:,1]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "GWgjD2IXZZE-",
        "outputId": "9814b4c6-3196-47c9-a7d7-1684a74eac49"
      },
      "outputs": [],
      "source": [
        "FS = (10, 8)\n",
        "fig, ax = plt.subplots(figsize=FS)\n",
        "# Make points translucent so we can visually identify regions with a high density of overlapping points\n",
        "ax.scatter(df_embs.x, df_embs.y, alpha=.075);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "liEcdqlybpls"
      },
      "outputs": [],
      "source": [
        "def plot_bg(bg_alpha=.01, figsize=(13, 9), emb_2d=None):\n",
        "    \"\"\"Create and return a plot of all embeddings with very low opacity.\n",
        "    (Intended to be used as a basis for further plotting of a \n",
        "    subset of words.)\n",
        "    \"\"\"\n",
        "    if emb_2d is None:\n",
        "        emb_2d = embs_red\n",
        "    fig, ax = plt.subplots(figsize=figsize)\n",
        "    X = emb_2d[:, 0]\n",
        "    Y = emb_2d[:, 1]\n",
        "    ax.scatter(X, Y, alpha=bg_alpha)\n",
        "    return ax\n",
        "\n",
        "#def annotate_sample(n, n_ratings_thresh=0):\n",
        "#    \"\"\"Plot our embeddings with a random sample of n words annotated.  \"\"\"\n",
        "#    sample = mainstream_movies[mainstream_movies.n_ratings >= n_ratings_thresh].sample(\n",
        "#        n, random_state=1)\n",
        "#    plot_with_annotations(sample.index)\n",
        "\n",
        "def plot_by_pattern(pattern, **kwargs):\n",
        "    \"\"\"Plot all words matching the given regex pattern. \"\"\"\n",
        "    match_idx = df_embs.word.str.contains(pattern)\n",
        "    match_idx.fillna(value=False, inplace=True)\n",
        "    match = df_embs[match_idx]\n",
        "    return plot_with_annotations(match.index, **kwargs)\n",
        "\n",
        "def add_annotations(ax, label_indices, emb_2d=None, **kwargs):\n",
        "    if emb_2d is None:\n",
        "        emb_2d = embs_red\n",
        "    X = emb_2d[label_indices, 0]\n",
        "    Y = emb_2d[label_indices, 1]\n",
        "    ax.scatter(X, Y, **kwargs)\n",
        "\n",
        "def plot_with_annotations(label_indices, labels=None, alpha=1, **kwargs):\n",
        "    ax = plot_bg(**kwargs)\n",
        "    Xlabeled = embs_red[label_indices, 0]\n",
        "    Ylabeled = embs_red[label_indices, 1]\n",
        "    if labels is not None:\n",
        "        for x, y, label in zip(Xlabeled, Ylabeled, labels):\n",
        "            ax.scatter(x, y, alpha=alpha, label=label, marker='1',\n",
        "                       s=90,\n",
        "                      )\n",
        "        fig.legend()\n",
        "    else:\n",
        "        ax.scatter(Xlabeled, Ylabeled, alpha=alpha, color='green')\n",
        "    \n",
        "    return ax\n",
        "\n",
        "\n",
        "FS = (13, 9)\n",
        "def plot_region(x0, x1, y0, y1, text=True):\n",
        "    \"\"\"Plot the region of the mapping space bounded by the given x and y limits.\n",
        "    \"\"\"\n",
        "    fig, ax = plt.subplots(figsize=FS)\n",
        "    pts = df_embs[\n",
        "        (df_embs.x >= x0) & (df_embs.x <= x1)\n",
        "        & (df_embs.y >= y0) & (df_embs.y <= y1)\n",
        "    ]\n",
        "    ax.scatter(pts.x, pts.y, alpha=.6)\n",
        "    ax.set_xlim(x0, x1)\n",
        "    ax.set_ylim(y0, y1)\n",
        "    if text:\n",
        "        texts = []\n",
        "        for label, x, y in zip(pts.word.values, pts.x.values, pts.y.values):\n",
        "            t = ax.annotate(label, xy=(x, y))\n",
        "            texts.append(t)\n",
        "        adjust_text(texts, expand_text=(1.01, 1.05))\n",
        "    return ax\n",
        "\n",
        "def plot_region_around(word, margin=5, **kwargs):\n",
        "    \"\"\"Plot the region of the mapping space in the neighbourhood of the given word. \n",
        "    The margin parameter controls the size of the neighbourhood around the word.\n",
        "    \"\"\"\n",
        "    xmargin = ymargin = margin\n",
        "    match = df_embs[df_embs.word == word]\n",
        "    if len(match) != 1:\n",
        "      print(f\"len(match) = {len(match)}, but should be 1\")\n",
        "      return\n",
        "    row = match.iloc[0]\n",
        "    return plot_region(row.x-xmargin, row.x+xmargin, row.y-ymargin, row.y+ymargin, **kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HMHf2fwceSRa"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    from adjustText import adjust_text\n",
        "except ImportError:\n",
        "    def adjust_text(*args, **kwargs):\n",
        "        pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "id": "oi-OeLNpcLY2",
        "outputId": "99f78e42-9d48-42fd-ab04-a47a83ff5a6a"
      },
      "outputs": [],
      "source": [
        "plot_region_around('science', margin=4);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "id": "HOut72DHcOMF",
        "outputId": "481e8e0b-5e28-4623-e32e-ab992d109cf9"
      },
      "outputs": [],
      "source": [
        "plot_by_pattern('fire', figsize=(15, 9), bg_alpha=.05)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iyL8vROZkTbV"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "_draft": {
      "nbviewer_url": "https://gist.github.com/7f86253a46c5444491fbb7541857edfa"
    },
    "colab": {
      "collapsed_sections": [
        "-1AYZMUsZZE4",
        "0KegMqP0ZZE7"
      ],
      "provenance": []
    },
    "gist": {
      "data": {
        "description": "chapters/06_RNN/tweet_classifcation/tweeter_classification.ipynb",
        "public": true
      },
      "id": "7f86253a46c5444491fbb7541857edfa"
    },
    "hide_input": false,
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "nbTranslate": {
      "displayLangs": [
        "*"
      ],
      "hotkey": "alt-t",
      "langInMainMenu": true,
      "sourceLang": "en",
      "targetLang": "fr",
      "useGoogleTranslate": true
    },
    "notify_time": "30",
    "toc": {
      "colors": {
        "hover_highlight": "#DAA520",
        "running_highlight": "#FF0000",
        "selected_highlight": "#FFD700"
      },
      "moveMenuLeft": true,
      "nav_menu": {
        "height": "156px",
        "width": "252px"
      },
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": false,
      "threshold": 4,
      "toc_cell": true,
      "toc_position": {
        "height": "255px",
        "left": "561px",
        "right": "20px",
        "top": "179px",
        "width": "266px"
      },
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "vscode": {
      "interpreter": {
        "hash": "bb3398f4b21c7b026dd5874af3f954bf25f1e8ff81e25d82a94abcbbaacf760b"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00ba227326f346e8b98c51ee6d05e01f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6595d9675c4d46899cf8a5e5cefbdf21",
            "placeholder": "​",
            "style": "IPY_MODEL_d7bc4b293fe248efa48025472bf3d359",
            "value": "training routine: 100%"
          }
        },
        "0cd2842f1dfb4f08a143b35d866d19b3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d3ae14466734acabc7f19c46016526f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "21441c5cd817431d82a016e9786e8cd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_00ba227326f346e8b98c51ee6d05e01f",
              "IPY_MODEL_65e57d46202f4114b3e525c977bedd6e",
              "IPY_MODEL_b484be9c0b16436f83aaf2ca963cad8c"
            ],
            "layout": "IPY_MODEL_4120637f7153488fbc43e8b5202573f8"
          }
        },
        "2f3c745809de431a9c13386ae8246c0a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3932c0ef68fb488ab1d0f434e88384f0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40245d3d23af46f3be8d0d2aebd908b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4120637f7153488fbc43e8b5202573f8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "451b34e0d9da47728514d2cc9a779802": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_49db9eac1d094b7eb467742f556dceeb",
              "IPY_MODEL_6714814012364f13a69b2c7df5d41506",
              "IPY_MODEL_f1a4f44da5d845f08086b69d4645741c"
            ],
            "layout": "IPY_MODEL_0cd2842f1dfb4f08a143b35d866d19b3"
          }
        },
        "49db9eac1d094b7eb467742f556dceeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c16919376604f86bfb89675549deb5d",
            "placeholder": "​",
            "style": "IPY_MODEL_4e63411a3aff410eb3d1654008296cd8",
            "value": "split=val:  96%"
          }
        },
        "4c3bd07439e6437591c6b5091c9c8e0e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e63411a3aff410eb3d1654008296cd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "532aee68a57b4a34b003df862bceac8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56b18987e1ca4092b65459ac1d1e0739": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6595d9675c4d46899cf8a5e5cefbdf21": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65e57d46202f4114b3e525c977bedd6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c3bd07439e6437591c6b5091c9c8e0e",
            "max": 6,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_adc35ef77ca544fe8dbbf4c4e55ee937",
            "value": 6
          }
        },
        "6714814012364f13a69b2c7df5d41506": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3932c0ef68fb488ab1d0f434e88384f0",
            "max": 27,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c4af50d8e8a34aa3a1ec0c1cf45e10da",
            "value": 26
          }
        },
        "68dc441427fb4b0d870417a2a600d39b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e1b376c05a145f6884e176a8fb78f79",
            "max": 126,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1d3ae14466734acabc7f19c46016526f",
            "value": 125
          }
        },
        "6b28aa01758d4d0f83189e0cf9311554": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e1b376c05a145f6884e176a8fb78f79": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c16919376604f86bfb89675549deb5d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ded9d634bc548a790cb707c30234ebb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b28aa01758d4d0f83189e0cf9311554",
            "placeholder": "​",
            "style": "IPY_MODEL_a68e5545489447bbb44e2ef989b2e076",
            "value": " 125/126 [03:12&lt;00:00,  4.43it/s, acc=19.2, epoch=5, loss=4.69]"
          }
        },
        "a23a795837e74365a35f241ece6ee856": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aa817f7466ce440694ec0a8c7f1d6d38",
              "IPY_MODEL_68dc441427fb4b0d870417a2a600d39b",
              "IPY_MODEL_8ded9d634bc548a790cb707c30234ebb"
            ],
            "layout": "IPY_MODEL_c04a8b56bfd54bffa51f1f0366cb0069"
          }
        },
        "a68e5545489447bbb44e2ef989b2e076": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa817f7466ce440694ec0a8c7f1d6d38": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56b18987e1ca4092b65459ac1d1e0739",
            "placeholder": "​",
            "style": "IPY_MODEL_f5fe46da9bd4485886dfb88536d337c9",
            "value": "split=train:  99%"
          }
        },
        "adc35ef77ca544fe8dbbf4c4e55ee937": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b484be9c0b16436f83aaf2ca963cad8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0946e4a05314f9eba0c9bfdd0ca3671",
            "placeholder": "​",
            "style": "IPY_MODEL_40245d3d23af46f3be8d0d2aebd908b3",
            "value": " 6/6 [03:16&lt;00:00, 32.41s/it]"
          }
        },
        "c04a8b56bfd54bffa51f1f0366cb0069": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4af50d8e8a34aa3a1ec0c1cf45e10da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d0946e4a05314f9eba0c9bfdd0ca3671": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7bc4b293fe248efa48025472bf3d359": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f1a4f44da5d845f08086b69d4645741c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f3c745809de431a9c13386ae8246c0a",
            "placeholder": "​",
            "style": "IPY_MODEL_532aee68a57b4a34b003df862bceac8e",
            "value": " 26/27 [03:16&lt;00:00,  7.45it/s, acc=20.7, epoch=5, loss=5.42]"
          }
        },
        "f5fe46da9bd4485886dfb88536d337c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
