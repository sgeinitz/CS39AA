{"cells":[{"cell_type":"markdown","metadata":{},"source":["# CS 39AA - Notebook 13a: Text Generation with (pre-trained) GPT-2\n","\n","Using a pre-trained transformer model, let's see what kind of text generation results we can get. We'll later see how this compares when we fine-tune this model using a corpus of our choice. To facilitate a comparison between the two we will use the same prompt for both. \n","\n","The hugginface documentation on how to do text generation with a pre-trained model can be found here:\n","* https://huggingface.co/transformers/v4.0.1/task_summary.html#text-generation\n"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[],"source":["import pandas as pd\n","from transformers import AutoModelForCausalLM, AutoTokenizer\n","from transformers import set_seed"]},{"cell_type":"markdown","metadata":{},"source":["The model we're choosing to use is the GPT-2 Medium model, which is the second smallest of the four GPT-2 models available (small, medium, large, and extra large). This can be found here:\n","* https://huggingface.co/gpt2-medium"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ae85e7f191be46529241c7857415dda0","version_major":2,"version_minor":0},"text/plain":["Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["MODEL_NAME = 'gpt2-medium'\n","\n","model = AutoModelForCausalLM.from_pretrained(MODEL_NAME)\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["prompt = \"The old bullfighter fell and \"\n","inputs = tokenizer.encode(prompt, add_special_tokens=False, return_tensors=\"pt\")"]},{"cell_type":"code","execution_count":52,"metadata":{},"outputs":[],"source":["set_seed(41)\n","prompt_length = len(tokenizer.decode(inputs[0], skip_special_tokens=True, clean_up_tokenization_spaces=True))\n","outputs = model.generate(inputs, max_length=30, do_sample=True, top_k=1000, temperature=1, num_return_sequences=10, \n","                         pad_token_id=tokenizer.eos_token_id) #top_p=0.95, \n"]},{"cell_type":"code","execution_count":53,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["ret_seq0: The old bullfighter fell and fractured his skull. There was a massive hole in the body of Khall and that week, the \"overrun\" \n","    (len(generated) = 23) \n","\n","ret_seq1: The old bullfighter fell and hit the ground, covered in blood, head to feet, surrounded by unconscious rivals: Lord Purnell, renowned for \n","    (len(generated) = 22) \n","\n","ret_seq2: The old bullfighter fell and the walls of his mask now looked strangely familiar. It might become his weapon again.  That looks like it could \n","    (len(generated) = 25) \n","\n","ret_seq3: The old bullfighter fell and broke his liver, ate several bruised bones and sustained major injuries to his spine. Maywood reported the incident to authorities but \n","    (len(generated) = 26) \n","\n","ret_seq4: The old bullfighter fell and wounded another opponent before the fight ended just as the scene was catching fire and smoke billowed in the background. Another bull \n","    (len(generated) = 27) \n","\n","ret_seq5: The old bullfighter fell and his family got out. Our older daughter was hurt.\"  He later told investigators the girl had been playing on a \n","    (len(generated) = 25) \n","\n","ret_seq6: The old bullfighter fell and hit the ground.  They fought over the bowl pan, and then the boxer threw up his arms and chased after \n","    (len(generated) = 25) \n","\n","ret_seq7: The old bullfighter fell and the new bull!—Jesse Lee, \"Me in White\" P.S.—Here are some pictures of me \n","    (len(generated) = 18) \n","\n","ret_seq8: The old bullfighter fell and got his liver or he needs a heart transplant and I don't think Marty Farber would appreciate it.\"  What \n","    (len(generated) = 24) \n","\n","ret_seq9: The old bullfighter fell and fell, crying out 'Miss! Miss!' \"  My wife and Dr. Hygieia started to tell me \n","    (len(generated) = 20) \n","\n"]}],"source":["for i in range(len(outputs)):\n","    generated = tokenizer.decode(outputs[i])\n","    len_gen = len(outputs[i])\n","    generated = generated.replace('\\n', ' ') # remove new line characters from generated text\n","    print(f\"ret_seq{i}: {generated} \\n    (len(generated) = {len(generated.split())}) \\n\")\n","    #print(f\"ret_seq{i}: {generated} \\n    (len(generated) = {len_gen}) \\n\")"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"data":{"text/plain":["torch.Size([50])"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["outputs[0].shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# upload my own model to huggingface\n","# https://huggingface.co/transformers/model_sharing.html\n","# https://huggingface.co/transformers/model_sharing.html#how-to-share-your-model-with-the-community\n"]}],"metadata":{"kernelspec":{"display_name":"torch13","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"67f030e82dc83e46e375c9862143c2f050702bf26aeee9494179d0591d712143"}}},"nbformat":4,"nbformat_minor":2}
